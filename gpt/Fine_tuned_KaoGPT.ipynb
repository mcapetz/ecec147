{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# GPT-2 Fine-Tuning Tutorial with PyTorch & Huggingface in Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf3Qw77SZGbS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "LiyuRMmWM-JV",
        "outputId": "8c63536b-5892-45cb-9ff4-a54ca3bc6179",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# fixes some random encoding errors\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "0NmMdkZO8R6q",
        "outputId": "b221d212-c5bc-4f23-a10f-e96dc5df4c20",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "JCCeyhuDHdOu",
        "outputId": "fea3ff12-c60c-4a36-c2a7-287a14d0d9fe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# % matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "uVZeC26UOmjo",
        "outputId": "e2aa659e-29f1-4de5-9956-9d2ce004115a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# So that the generated outputs wrap around\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "satxtOn9CzgR",
        "outputId": "84c9f892-5aa7-4528-ddc7-2b810c15b0fd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Mar 19 20:20:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    29W /  70W |   8153MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdCML6Parvv"
      },
      "source": [
        "# Create Training Set\n",
        "\n",
        "KAO transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "_EYFrNxr-TYb",
        "outputId": "c157a86e-9614-4216-cc42-0925fcd48c40",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# mount my Google Drive directory /and access the training data located there\n",
        "gdrive_dir = '/content/gdrive/'\n",
        "data_path = 'gdrive/MyDrive/GPT2test/'\n",
        "\n",
        "drive.mount(gdrive_dir, force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "G_DWAMe1FopX",
        "outputId": "f8dff240-9c4b-4d3f-fa61-56976ebadedb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e69d9903-5dd2-47c9-889f-44284c491305\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A question from Brandon. So just out of curios...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A second challenge is that features of the res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Actually, it's weird to see. We have really go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>again. Okay, so, uh, Wingshee, your question w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>again. Okay, so, uh, Wingshee, your question w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>You may feel the pace of the class is somewhat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>You may feel the pace of the class is somewhat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>You may feel the pace of the class is somewhat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>You would have the access to going from zero t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>Your output will have either amplitude distort...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>523 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e69d9903-5dd2-47c9-889f-44284c491305')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e69d9903-5dd2-47c9-889f-44284c491305 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e69d9903-5dd2-47c9-889f-44284c491305');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  Text\n",
              "0    A question from Brandon. So just out of curios...\n",
              "1    A second challenge is that features of the res...\n",
              "2    Actually, it's weird to see. We have really go...\n",
              "3    again. Okay, so, uh, Wingshee, your question w...\n",
              "4    again. Okay, so, uh, Wingshee, your question w...\n",
              "..                                                 ...\n",
              "518  You may feel the pace of the class is somewhat...\n",
              "519  You may feel the pace of the class is somewhat...\n",
              "520  You may feel the pace of the class is somewhat...\n",
              "521  You would have the access to going from zero t...\n",
              "522  Your output will have either amplitude distort...\n",
              "\n",
              "[523 rows x 1 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(f'{data_path}transcript_data/kaorpus.csv')\n",
        "df.dropna(subset=['Text'], inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "FMHIn_adhOIS",
        "outputId": "fae1a21e-9e6e-43e0-d0d9-d399c037f534",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "897.0\n",
            "32767\n"
          ]
        }
      ],
      "source": [
        "print(np.median([len(d) for d in df.Text]))\n",
        "print(np.max([len(d) for d in df.Text]))\n",
        "\n",
        "# the c147 transcripts are way longer than the other rows so we split it into ~1000 character rows\n",
        "data = list()\n",
        "for d in df.Text:\n",
        "  if len(d) < 2000:\n",
        "    data.append(d)\n",
        "  else:\n",
        "    d =  [e+'.' for e in d.split('.') if e]\n",
        "    for i in range(len(d) // 10):\n",
        "      data.append(\"\".join(d[i: min(i + 10, len(d))]))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "NkYxQ5qFkUfu",
        "outputId": "1b66d809-d222-41b5-df9e-8c1804bfb634",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "2289"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.max([len(d) for d in data])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are at most 2289 characters per row, so this is good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ1oK0kXaV5p"
      },
      "source": [
        "We need to get an idea of how long our training documents are.\n",
        "\n",
        "I'm not going to use the same tokenizer as the GPT2 one, which is a [byte pair encoding tokenizer](https://blog.floydhub.com/tokenization-nlp/). Instead, I'm using a simple one just to get a rough understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "cKsH2sU0OCQA",
        "outputId": "21fc923b-8b35-4877-bbb4-345f762f4841",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-51-cb8db075aad6>:12: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(doc_lengths)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: ylabel='Density'>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "doc_lengths = []\n",
        "\n",
        "for d in data:\n",
        "\n",
        "    # get rough token count distribution\n",
        "    tokens = nltk.word_tokenize(d)\n",
        "\n",
        "    doc_lengths.append(len(tokens))\n",
        "\n",
        "doc_lengths = np.array(doc_lengths)\n",
        "count = 0\n",
        "sns.distplot(doc_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "u6P6bTItJEIj",
        "outputId": "4114a5de-cbed-45fd-b33d-b480c2adbac4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the max token length   \n",
        "len(doc_lengths[doc_lengths > 768])/len(doc_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "63t_69HjlwAj",
        "outputId": "403b0640-bf4f-41af-c706-f7cba2b91f86",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "184.73252562907734"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.average(doc_lengths)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuq5bqdr4_a6"
      },
      "source": [
        "Even though these token counts won't match up to the BPE tokenizer's, I'm confident that all rows will fit under the 768 embedding size limit for the small GPT2 model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMml12FJGjPW"
      },
      "source": [
        "# GPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Z474sSC6oe7A",
        "outputId": "6bac996f-8528-44dd-ec32-9abcc6fcc3e9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the GPT tokenizer.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>') #gpt2-medium\n",
        "tokenizer.add_tokens(['<|answer|>']) # for question and answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "sh0XKuDvnryn",
        "outputId": "a11daa9f-3cf2-4396-a034-75f125f6f3a9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n"
          ]
        }
      ],
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# PyTorch Datasets & Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgZoOYkxZfx"
      },
      "source": [
        "GPT2 is a large model. Increasing the batch size above 2 has lead to out of memory problems. This can be mitigated by accumulating the gradients but that is out of scope here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "scqrzmqhV__z",
        "outputId": "0f6b3c7e-c14e-42d5-9612-48af83c8911d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqGMee7Isfpx"
      },
      "source": [
        "I'm using the standard PyTorch approach of loading data in using a [dataset class](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).\n",
        "\n",
        "I'm passing in the tokenizer as an argument but normally I would  instantiate it within the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "U_XJVIetKN-h",
        "outputId": "7b3a4cad-7f9f-42ba-b795-c748a11aa677",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx] "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "89Z7aYUgpWrd"
      },
      "source": [
        "To understand how I've used the tokenizer, it's worth reading [the docs](https://huggingface.co/transformers/main_classes/tokenizer.html). I've wrapped each row in the bos and eos tokens.\n",
        "\n",
        "Every tensor passed to the model should be the same length.\n",
        "\n",
        "If the bio is shorter than 768 tokens, it will be padded to a length of 768 using the padding token. In addition, an attention mask will be returned that needs to be passed to the model to tell it to ignore the padding tokens. \n",
        "\n",
        "If the bio is longer than 768 tokens, it will be truncated without the eos_token. This isn't a problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Xza_O1_rD7yh",
        "outputId": "6a0ec40d-669c-41af-f449-34418648f1ba",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  965 training samples\n",
            "  108 validation samples\n"
          ]
        }
      ],
      "source": [
        "dataset = GPT2Dataset(data, tokenizer, max_length=768)\n",
        "\n",
        "# Split into training and validation sets\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "x0WeP5PREUuy",
        "outputId": "46d989ad-4db1-4104-d6ce-1c253019c74e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "# Finetune GPT2 Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "gFsCTp_mporB",
        "outputId": "0084de52-317d-4278-d3de-9bc025cf18a8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# I'm not really doing anything with the config buheret\n",
        "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
        "\n",
        "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "pBEVY2PYSTXJ",
        "outputId": "5e0f1dd6-2ea7-4405-ed05-73b3289dc8fc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4 # turn this down when finetuning on the QA dataset so it doesn't overfit and mess up the QA capabilities that much\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 500\n",
        "\n",
        "params = {\n",
        "    'epochs': epochs,\n",
        "    'lr': learning_rate,\n",
        "    'warmup_steps': warmup_steps,\n",
        "    'eps': epsilon,\n",
        "    'sample_every': sample_every\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "GLs72DuMODJO",
        "outputId": "9a6533d4-b025-436f-f5e8-4ae95304524f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "-p0upAhhRiIx",
        "outputId": "883c4b58-52a4-4e88-e33e-333f69503dbb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "gpt6tR83keZD",
        "outputId": "122c1afd-2de2-44b5-a207-313df981188d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "mUHW6xbJefWZ",
        "outputId": "7dc61b52-a0f7-4105-ac88-5057aa3ae002",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load a saved model. Change the model path \n",
        "MODEL_PATH = f'{data_path}model_save/gpt2-base3.pt'\n",
        "\n",
        "checkpoint = torch.load(MODEL_PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "vCPohrZ-CTWu",
        "outputId": "df1642de-e4de-4746-92ad-a69d9bf6367a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 483/483 [04:10<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.54\n",
            "  Training epoch took: 0:04:11\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.68\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 302/483 [02:33<01:31,  1.97it/s]"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "from tqdm import tqdm\n",
        "MODEL_PATH = f'{data_path}model_save/gpt2-base3.pt'\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "try:\n",
        "  checkpoint = torch.load(MODEL_PATH)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "except:\n",
        "  epoch = 0\n",
        "\n",
        "for epoch_i in range(epoch, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, #you're basically training the model to be able to output your inputs\n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "            # Create output directory if needed\n",
        "            if not os.path.exists(f\"{data_path}/model_save\"):\n",
        "                os.makedirs(f\"{data_path}/model_save\")\n",
        "\n",
        "            print(\"Saving model to %s\" % MODEL_PATH)\n",
        "\n",
        "            torch.save({\n",
        "              'epoch': epoch_i,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss,\n",
        "            }, MODEL_PATH)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Uyip-x1Clogy",
        "outputId": "c4300e89-bd2a-4eed-bb9f-2ebd74c04c06",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to gdrive/MyDrive/GPT2test/model_save/gpt2-qa+ft1.pt\n"
          ]
        }
      ],
      "source": [
        "# save the model if you want it\n",
        "if not os.path.exists(f\"{data_path}/model_save\"):\n",
        "    os.makedirs(f\"{data_path}/model_save\")\n",
        "\n",
        "print(\"Saving model to %s\" % MODEL_PATH)\n",
        "\n",
        "torch.save({\n",
        "  'epoch': 5,\n",
        "  'model_state_dict': model.state_dict(),\n",
        "  'optimizer_state_dict': optimizer.state_dict(),\n",
        "  'loss': loss,\n",
        "  'params': params\n",
        "}, MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "6O_NbXFGMukX",
        "outputId": "8e447345-ead7-49e2-e1e1-8f9ffec307f9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b38a5abe-65c0-4ebc-b1d6-4a22404a940c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.52</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0:04:08</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0:04:07</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.44</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0:04:08</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0:04:07</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0:04:08</td>\n",
              "      <td>0:00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b38a5abe-65c0-4ebc-b1d6-4a22404a940c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b38a5abe-65c0-4ebc-b1d6-4a22404a940c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b38a5abe-65c0-4ebc-b1d6-4a22404a940c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               1.52         0.73       0:04:08         0:00:09\n",
              "2               0.62         0.50       0:04:07         0:00:09\n",
              "3               0.44         0.41       0:04:08         0:00:09\n",
              "4               0.35         0.39       0:04:07         0:00:09\n",
              "5               0.31         0.39       0:04:08         0:00:09"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "68xreA9JAmG5",
        "outputId": "421f91f4-a64f-4a52-c536-fe6471c6adf8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GfjYoa6WmkN6"
      },
      "source": [
        "## Display Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PIiVlDYCtSq",
        "outputId": "5b897953-285d-4d34-a33f-ee3cedb65a91",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50260, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (768, 2304)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (768, 3072)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (3072, 768)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLf6rbRglYhQ"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "SMMoM-evQVeW",
        "outputId": "e226779b-8937-4979-dd51-6f2cd9bc29a3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def predict(model, tokenizer, prompt, qa = False):\n",
        "    model.eval()\n",
        "    prompt = \"<|startoftext|>\" + prompt\n",
        "    if qa:\n",
        "      prompt += \"<|answer|>\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    sample_outputs = model.generate(\n",
        "                                    **inputs, \n",
        "                                    #bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    # top_k=50, \n",
        "                                    max_length = len(inputs['input_ids'][0]) + 50,\n",
        "                                    top_p=0.90, \n",
        "                                    num_return_sequences=3\n",
        "                                    )\n",
        "\n",
        "    for i, sample_output in enumerate(sample_outputs):\n",
        "        print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FVGqNAj7Jw-H"
      },
      "source": [
        "## GPT-base Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "3yDLh-DeoCXH",
        "outputId": "73c7ef38-2fdb-47dc-f81b-dd72f2e576bf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: One of the reasons to prefer small kernel sizes over larger ones is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? The first is that you don't have to do extra computation and you don't have to deal with batch normalization and the propagation of neural networks. You don't have to do extra computation and you can\n",
            "\n",
            "\n",
            "1: One of the reasons to prefer small kernel sizes over larger ones is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? Yes. The more room you have, the more room you have in your code to train neural networks. Also, you don't have to do extra computation. You can just do the computation and the loss\n",
            "\n",
            "\n",
            "2: One of the reasons to prefer small kernel sizes over larger ones is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? First off, because it's de facto standard for neural networks today, which is that each of these different topics, is there new architectures and how their needs for particular applications? All right. And then\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"One of the reasons to prefer small kernel sizes over larger ones is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "4nruGjTaJXqD",
        "outputId": "1c6f0221-f58b-4519-e821-89aba6045040",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? Here, let me go ahead and recap what we're going to do. We're going to go over the pros and cons of each of these architectures.\n",
            "\n",
            "\n",
            "1: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? Are there any particular questions from this slide? Alright, so here's the last part of it. In our question that you're trying to solve for, we had a scalar epsilon. Epsilon, I believe was equal to something like one-half Z transpose Z. And I want to compute d Epsilon dW, where then I would use my chain rule, which we derived last lecture goes from right to left. Right. This will be called a recursion, or\n",
            "\n",
            "\n",
            "2: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? So remember, when we're doing classification we're trying to find structure in the data, which comprises the first-order, the second quarter of being acquired. And we still have 50,000 images for each category.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "8yrzD8I-oElj",
        "outputId": "796991cf-603d-4640-8b2c-1cb3ce37d543",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? Because before we begin, we have to understand how our eyes work. We have to be able to perceive the movement of a robotic arm. We have to be able to make movements based on the movements we make. And that includes both our eye movements\n",
            "\n",
            "\n",
            "1: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? The key driver of neural network architectures, which we should also get to likely by the end of lecture today, is that they are inspired from biological neurons. So they have inputs which are these arborist like regions of the neuron called dendrites\n",
            "\n",
            "\n",
            "2: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? We'll discuss briefly in the assignments, but a lot of what we've done in the past is we've designed the project to be fairly simple, but with the following goals in mind. First, we're going to be able to do tasks based\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "vHCd2251k6Zn",
        "outputId": "c07f7023-1c43-436e-cb16-6f60f1b31271",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. So today, I'm going to talk about a common filter whose behavior is essentially the same as that of the Fourier transform with respect to period. Right. And we have, in the lectures, done the Fourier transform example where we had the\n",
            "\n",
            "\n",
            "1: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. And then the motivation of why we can't use late days on the projects is because they're not totally reliable. So at the end of the day, we're going to be using VAEs and we're not going to have to deal with the\n",
            "\n",
            "\n",
            "2: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. And so what we're going to cover is a class that has seen some recent advances in computer science and has been very fun. And we'll talk about some of the recent advances in machine learning. And we'll also talk about some of the recent\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "xSbWxx0hlECt",
        "outputId": "69cfa3c5-a8e6-4c02-d3a8-5d294b20fe1a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. And then I'm going to take this expression and I'm going to take my model code and I'm going to derive it for this probability. And then what that means is that if I have a distribution, where I have a probability of x given\n",
            "\n",
            "\n",
            "1: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. So let's say that the xk given xk is a probability distribution with k minus 1. And that we know from our definition of a probability distribution that this k is a product of the probability of xk given xk and that it's\n",
            "\n",
            "\n",
            "2: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. And then we'll look at later slides.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "q8vzTHsAl5bj",
        "outputId": "e5fbeb39-0a00-4d00-8b05-643128b05b59",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. And so for the HFT that we're going to want to be able to have the spectrum and frequency response in that case, we would need a constant of some sigma. So this would be that signal that is going to be a sigma\n",
            "\n",
            "\n",
            "1: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. And then we could say that the depth should be 6,000,000 or something. So I'm confused. Yeah, actually, what would it be if we had a 2D block where we have 100 of these nodes? And I'm wondering\n",
            "\n",
            "\n",
            "2: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. I would need to take the time to consider that. And then I'm going to pause the video for one second and then I'm going to derive the neural data that we need for this model. So in the first example, there are two spikes\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "UqrDdDyLmQmE",
        "outputId": "87735fdc-8e40-4e8c-b247-3b05d8ebe033",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: This cat is very cute and he's in a good <|answer|>  correct, yeah. The correct question is he's in the correct number three, the correct number four, etc. But I think that's a bit too fast. Okay.\n",
            "\n",
            "\n",
            "1: This cat is very cute and he is my absolute favorite. I cat boy will be your instructor for this course and on behalf of all of you in this class, we will strive to release any questions that we may have on the project using Python. With that said,\n",
            "\n",
            "\n",
            "2: This cat is very cute and you all know that she is interested in learning. You can do that for her question and answer, etc. But we won't take any verbal questions from the homework. We just asked if she'd like to ask a question for the homework. I\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"This cat is very cute and\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "uY6Vm01Sm0eZ",
        "outputId": "2c209248-3842-47bf-bd2b-e310e830d0ea",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: In a world where machines had emotions and whatnot, what we want to do is we want to tell a story. And so if we want to tell a complex exponential, what we want to tell are these complex exponential s that we said are the points in time when the spikes occurred\n",
            "\n",
            "\n",
            "1: In a world where machines had emotions and not brains, there would be these neural spikes that are called kinematics. And what these spikes look like is they are moving in time. And they have no spikes. And the spikes look like if you were to move your arm over a\n",
            "\n",
            "\n",
            "2: In a world where machines had emotions like fear, it would be hard to imagine <|answer|>  rest of the <|answer|> <|answer|>  class being completely paralyzed by a computer cursor on the screen. And then in this hypothetical world, instead of being paralyzed, we would be doing tasks where the computer cursor\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"In a world where machines had emotions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "z-pcWlRZmq3j",
        "outputId": "390abc59-e87e-4596-cb58-6e0c2b7147bd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: The universe is a vast and mysterious place, full of wonders and secrets, and <|answer|>  answer to these questions is yes. So I'm going to provide this information for you to write to me, copy and paste to your computer, and so that you can have a fully connected internet connection to the ISS. All right.\n",
            "\n",
            "\n",
            "1: The universe is a vast and mysterious place, full of wonders and secrets. exact same exact thing as our sun system. All right. But, for the rest of the series, where does the name, or does it have the same meaning as a sun system that we have from ancient times\n",
            "\n",
            "\n",
            "2: The universe is a vast and mysterious place, full of wonders and secrets. <|answer|>  mystery. Okay. So why is it that we only have the last part of the class saying we have the last part of the class saying we have the last part of the class saying we have the last part of\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"The universe is a vast and mysterious place, full of wonders and secrets\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SC8WdnC8J7JV"
      },
      "source": [
        "## Using fine-tuned GPT (QA + FT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "DRL8GvzDKDy0",
        "outputId": "8cfd85e6-c203-45f2-d2e9-a3c73529d387",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: One of the reasons to prefer small kernel sizes over larger is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? <|answer|>  faster training\n",
            "\n",
            "\n",
            "1: One of the reasons to prefer small kernel sizes over larger is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? <|answer|> Boeing more properties.\n",
            "\n",
            "\n",
            "2: One of the reasons to prefer small kernel sizes over larger is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs? <|answer|>  better training times and better training times\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"One of the reasons to prefer small kernel sizes over larger is that smaller kernels have fewer parameters than larger ones, which can reduce the model's complexity and computational requirements. This can lead to faster training times and lower memory requirements. What are the benefits of using smaller kernel sizes in CNNs?\", qa = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "CVNjP-2mXyao",
        "outputId": "062b7cf3-1bd1-40b6-9b07-d765fe4f6058",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? <|answer|> time-learning\n",
            "\n",
            "\n",
            "1: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? <|answer|> propagation, speech, and text\n",
            "\n",
            "\n",
            "2: Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs? <|answer|>  Sorry probability signals\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) are two popular types of deep learning models that are used in different domains. RNNs are generally preferred over CNNs for processing sequential data, such as time-series data, speech, and text. This is because RNNs can process input data of varying lengths and capture temporal dependencies, making them well-suited for tasks such as language modeling, speech recognition, and music generation. Which use cases do we see RNNs preferred over CNNs?\", qa = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "BM-tXQBJPHOD",
        "outputId": "5dc3f245-6c02-468c-ba2e-2fddcf1cccd2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? It also helped to introduce the loss ofness at least? You're under the So You can do this for every single class or in a different room. So, the amount of noise in the essentially anonymous room here is very important. All right, so instead of an object's performance.\n",
            "\n",
            "\n",
            "1: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? <|answer|> reducing the error rate\n",
            "\n",
            "\n",
            "2: The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision? Well, this led to people who are taking the exam at Stanford University and have done physical and surface problems.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"The introduction of residual connections in ResNet led to much deeper networks being trained than previously possible. This allowed for much better performance on difficult computer vision tasks, such as image classification, object detection, and semantic segmentation. In fact, ResNet achieved state-of-the-art performance on the challenging ImageNet dataset, reducing the error rate by a significant margin compared to previous approaches. Why was ResNet such a big breakthrough in computer vision?\" qa=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "WzjkAvIKN9cr",
        "outputId": "6552bd50-9f87-4ac8-aedd-4e6c6b3d0465",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. All right. And the question is, why do we do like to have our two parts being equal to one. Yeah, what we do is we're going to talk about for now? A, you're going to be equal to the change that we do\n",
            "\n",
            "\n",
            "1: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. All right. I'm just going to get there a little bit about the phase change and what we would do is the change that we would take on the, I see the Fourier transform of the class. And we're going to change the distribution of the\n",
            "\n",
            "\n",
            "2: All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research. It'll be a very high level overview of the motivation for piazza. The first two are the first three problems, the first is that the essentially constant, essentially constant, right. So the second solution is that we're going to talk about these different\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"All right. All right, cool. Today, we'll just talk about the structure of this class and then introduce the problem that we'll talk about for the rest of this class, which is going to be related to my research.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "8bl-6r7gOKcr",
        "outputId": "bdc4b64a-9037-4aaa-b6ae-182d5bef65e2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. That would be true. We're going to try to use a spike spike like when it's going to be the spike that will make it the spike in every single spike. And so last lecture, we had talked about how this process would have\n",
            "\n",
            "\n",
            "1: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. We can take the number of questions, which is one more thing here. So the number of questions in this class. The number of questions that can be answered in this class is going to be over. And then when I can tell you what\n",
            "\n",
            "\n",
            "2: And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood. And then there's a number of instances that this does for each element of this expression which is called an extended matrix or a matrix for a computer plus the fact that, as in the example, the answer is over here. And the fact that\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"And okay, let's move on for now. So what we're gonna do is I'm going to take this expression over here. And we're going to actually write out what this means in terms of our models that we can derive our likelihood.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "CZbkHMz-Oa26",
        "outputId": "6963e215-a365-4764-cf1f-5f31dbaf63f9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. And that's what I would do here is a summary of how we would do and the first factor is this expression here. So if I do the first factor, A is that the second factor is the probability that I'm going to move here. Yeah, that is, what I know that. Let me just do the second of my inputs\n",
            "\n",
            "\n",
            "1: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. But when you look at the absolute infinite points of these terms, that's the absolute point of this impulse. Okay, so here, this will be the second unit. So in this case, the absolute point of this impulse is the absolute same as the absolute, i, that's this impulse. This is a function of the absolute potential of\n",
            "\n",
            "\n",
            "2: Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values. That's my first principle. The real part, great. And so, thanks to that, we're going to give two more solutions and then the last part, we were going to try to get a real part. And then the number of spikes that have ever been given the height of the system in this case, it might be written as\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"Great, Yeah, So now another student is saying, in this case, would it make sense to match the depth because that's our RGB values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "RJDeCHfOPJ-T",
        "outputId": "e582e50f-91f4-4c0d-b827-6f054d130ace",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: This cat is very cute and fairly consistent And so in the past, we just won't take a bit of it Any questions on this or discussions I already have a Zoom? Alright The reason that I wanted to take the tools that I'm going to take the tools that I was planning to take, which is that I was planning to take the tools that I started to compute And I would want to highlight So I would cover up two co-dimensional neural networks, which is that each of these\n",
            "\n",
            "\n",
            "1: This cat is very cute and then the cell is probably the act of planning this class And it's going to be a function of exponential and this also tells me I'll want to explain that if I take my head of an object and I will be able to know how to proceed this homework, I know that if I go ahead and I know that I'll tell me what I will do is I'm sorry. And I'll know that if I were to take my head of this class and\n",
            "\n",
            "\n",
            "2: This cat is very cute and in general at least when you're only controlling the big dacastrony or a much larger axis and you don't see that they just have the same exact same exact out. And if you've been taking dacastrony with ten other locations or the same location, what we would have is we would take the comment and then I would take the sign that would take the form that we know and update it into a sign. And this will be\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"This cat is very cute and\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "bnG1Ff6XkE_c",
        "outputId": "c0fd6265-7fbc-4997-c0dc-25bb42b355d0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: In a world where machines had emotions, the monkey would be the controlling center of that, the monkey would be the center of what the monkey was thinking. That would be the baseline state. And the monkey would be instructed to plan to that baseline state until the next training phase when the monkey reaches to targets of zero mean and variance. All right. And then we said, and we talked about this idea, which is that we would train the monkey to plan to the next reach target, and then if he reaches to target of zero\n",
            "\n",
            "\n",
            "1: In a world where machines had emotions and not just physical characteristics, how <|answer|>  brain works, it's a complex system where what we want to do is we want to build a system that can interface with, for example, light or sound signals, like the perception of what is happening on the screen or audio. And light or sound signals can be very helpful for this function because in a normal brain, light signals are attenuating. But if it's attenuating, the signal is attenuating. And if we want to build a system\n",
            "\n",
            "\n",
            "2: In a world where machines had emotions and speech recognition, how do we make intuitively sense of the stimuli? Through auditory prosthesis, the participant has the ability to make analogously accurate predictions about the stimuli. Through the auditory prosthesis, the participant also has the ability to make movements. Through the implant, the participant has the option to make a custom plan to move the robotic arm and make a wish. It is to be a fully connected, natural language processing prosthesis that we, in this bid to simulate a brain-m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"In a world where machines had emotions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "vW3xYhNFSMDc",
        "outputId": "a2284603-3460-4875-ea10-12edb5c8832e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: The universe is a vast and mysterious place, full of wonders and secrets about how these plot models are implementing or meeting via reason of observation. So we're going to cover variational autoencoders, but we'll do some criminalization and neural networks, but the output of the electric field. And then we'll cover the neural network architecture. And we're also going to derive a way to this information that we're going to use to solve the problems for this class. And so we\n",
            "\n",
            "\n",
            "1: The universe is a vast and mysterious place, full of wonders and secrets, so like the rest of the universe, they're very helpful in understanding that the world is a hope that's given them exposure to all wrongs and gets them to the world. All right. So the world reaches to the world, we know from a few things that had close relationships to the world. And so now we're going to take a few more details. The first is that that they are now thought to\n",
            "\n",
            "\n",
            "2: The universe is a vast and mysterious place, full of wonders and secrets, that's where each of those are connected by knowledge and being communicated all the way until one second on the last page of the neural network, we will see that basically the more strictly coded examples that we would then look at in the first slide of the neural network, which we would use for it at the end of last lecture, which is that they would, would, would, would, would, would, would,\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predict(model, tokenizer, \"The universe is a vast and mysterious place, full of wonders and secrets\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
